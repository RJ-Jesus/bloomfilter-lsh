\documentclass[a4paper,11pt,openright,oneside]{report}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[portuguese]{babel}
\usepackage{graphicx}
\usepackage[backend=biber, style=ieee]{biblatex}
\usepackage{csquotes}
\usepackage{blindtext}
\usepackage[printonlyused]{acronym}
\usepackage{hyperref}
\usepackage{indentfirst}
\usepackage[titletoc,title]{appendix}
\usepackage{mathtools}
\usepackage{amsmath,amsthm,amsfonts,amssymb}
\usepackage{caption}
\usepackage{subcaption}
\newcommand{\RNum}[1]{\uppercase\expandafter{\romannumeral #1\relax}}

\bibliography{report.bib}

\begin{document}

\begin{titlepage}
\begin{center}

{\vspace*{50mm}\textsc{\Huge\textbf{Bloom-filter + Locality-sensitive hashing}\\ \small{Métodos Probabilísticos para Engenharia Informática}}}\\[2cm]
{\textsc{\small\textbf{Universidade de Aveiro}}}\\[0.5cm]
{\small Pedro Martins 76551\\Ricardo Jesus 76613}\\[0.5cm]
{\small	17 de Dezembro de 2015}\\

\begin{figure}[b]
\center
\graphicspath{}
\includegraphics[height=2cm]{ua.pdf}
\end{figure}

\end{center}

\end{titlepage}

\title{\textbf{Bloom-filter + Locality-sensitive hashing}\\[1cm]\textsc{\small {Departamento de Electrónica, Telecomunicações e Informática} \\ \large {UNIVERSIDADE DE AVEIRO}}}
\author{Pedro Martins 76551, pbmartins@ua.pt\\Ricardo Jesus 76613, ricardojesus@ua.pt}
\date{17 de Dezembro de 2015}

\maketitle

\pagenumbering{roman}

\begin{abstract}

ABSTRACT

\end{abstract}

\tableofcontents
%\listoftables
\listoffigures

\clearpage
\pagenumbering{arabic}

\chapter{Introdução}
\label{chap.introdução}

Na área da informática, é, por exemplo, muitas vezes necessário saber se algo pertence a um certo conjunto de forma eficiente. A solução mais óbvia seria percorrer todo o conjunto e comparar, um a um, todos os elementos até encontrar aquele que se procurava inicialmente. No entanto, este método é deveras ineficiente especialmente se se estiver a trabalhar com conjuntos com milhões ou mais elementos. É aqui que surgem estruturas como \textit{Bloom-filters}. 

\textit{Bloom-filters} usam geralmente várias funções de dispersão (ou \textit{hashing}) para determinar a pertença de um dado elemento num conjunto (\textit{set}). São muito utilizados em grandes conjuntos de dados e em diversas aplicações, como corretores ortográficos de computadores, \textit{smartphones}, etc., análise textual, entre outras. Contudo, e sendo uma estrutura probabilística, acarreta um erro associado.

Outra técnica bastante relevante em situações onde é ``impossível'' guardar e trabalhar enormes conjuntos de dados é o de \textit{MinHash}. Muitas vezes, a par com esta, aparece também o método de \textit{Locality-sensitive hashing (LSH)}, com aplicações usuais em \textit{clustering} de informação e procura de vizinhos próximos a um dado elemento (\textit{nearest neighbor search}).

Neste trabalho, foi desenvolvido em MATLAB um \textit{Bloom-filter}, um \textit{MEX file} fazendo de interface para uma família de funções de \textit{hash} escritas em C++ e ainda um módulo com capacidade de \textit{nearest neighbor search} utilizando \textit{MinHash} para gerar uma representação de diferentes documentos a serem tratados.

Neste contexto considere-se a filtragem de correio electrónico, algo largamente realizado por diversas empresas nos dias de hoje, tanto para o separar por temas como para evitar \textit{spam} (i.e. lixo). Usando as técnicas acima, torna-se possível a implementação de um modelo probabilístico de categorização de correio eletrónico.

\chapter{Bloom-filter}
\label{chap.bloom}

\textit{Bloom-filters} são estruturas de dados probabilísticas que utilizam uma ou várias funções de \textit{hash} para determinar a pertença de um dado elemento num \textit{set}. Internamente, habitualmente utilizam um vetor de \textit{bits}. Neste trabalho, utilizou-se um vetor de \textit{bytes} visto que a linguagem em que o módulo foi escrito (MATLAB) não suporta o tipo \textit{bit}. Para se tirar partido do espaço extra que se utilizou (\textit{byte vs bit}) e visto ser-nos útil mais tarde na aplicação realizada, o módulo foi implementado como um \textit{Counting filter}, onde, portanto, se mantém registo do número de elementos iguais que deverão ter sido adicionados ao filtro.

Desde que sejam utilizadas funções de \textit{hash} eficientes, mesmo que se opere sobre um conjunto com milhões ou milhares de milhões de elementos, determinar a pertença ou não pertença de um valor nesse conjunto será sempre um processo significativamente mais rápido do que caso se iterasse sobre todo o \textit{set}, elemento a elemento, à procura daquele em questão. Este processo depende do número e da qualidade das funções de \textit{hash} utilizadas, bem como do tamanho do vetor interno.

Como estrutura probabilística que é, \textit{Bloom-filters} têm um erro associado, neste caso manifestando-se apenas em falsos positivos, i.e., se um \textit{Bloom-filter} indica que um elemento pertence a um conjunto, então \underline{provavelmente} ele pertence mesmo. Por outro lado, se um \textit{Bloom-filter} indica que um elemento não pertence a um conjunto, então \underline{definitivamente} não pertence. Tendo isto em mente, habitualmente os \textit{Bloom-filters} são dimensionados para um erro máximo admissível e para um determinado número de elementos que se tencione adicionar ao filtro.

Este erro depende do tamanho do vetor interno e do número de funções de \textit{hash} a utilizar. Estas funções devem ser descorrelacionadas entre si e em número variável (em função dos parâmetros para os quais o filtro deve ser dimensionado). Uma solução para o número variável de funções que se deve utilizar é, em vez de se utilizarem \texttt{k} funções diferentes, utilizar-se uma família de funções que garanta \texttt{k} funções descorrelacionadas.

Neste trabalho, utilizou-se a família de funções de dispersão denominada \textit{FarmHash}, desenvolvida pela Google, em que um dos argumentos, a \textit{seed}, permite especificar cada uma das funções da família. A sua implementação é disponibilizada em C++ pela empresa que a desenvolveu, e, portanto, de forma a poder ser utilizada ao longo do projeto, foi escrito um ficheiro \textit{MEX} que permite a interface entre código MATLAB e a função. Caso seja necessário, o ficheiro pode ser compilado executando (no directório onde os ficheiros \textit{.h} e \textit{.cpp} relativos à função se encontrem) \verb|mex FarmHash.cpp|.

\section{Atributos}
\label{sec.attributes}

Na implementação deste trabalho (ficheiro \textit{BloomFilter.m}) desenvolveu-se uma estrutura baseada num \textit{Counting Bloom-filter} (conta-se o número de vezes que cada elemento é adicionado ao filtro), com 5 atributos:

\begin{description}
\item[k]
Número de funções de \textit{hash} a utilizar.
\item[byteArray]
Estrutura de dados interna do filtro, vetor de \textit{bytes}.
\item[arraySize]
Tamanho do vetor de \textit{bytes}.
\item[amountAdded]
Número total de elementos adicionados ao \textit{array}.
\item[expectedMaxSize]
Tamanho do conjunto que se pretende adicionar ao vetor.
\end{description}

\section{Métodos}
\label{sec.methods}

No construtor da classe, são calculados os valores do tamanho do vetor (\texttt{arraySize}) e do número de funções de \textit{hash} necessárias, consoante os valores passados como argumentos do próprio construtor: a probabilidade de falsos positivos, i.e., o erro admissível (\texttt{falsePositiveProbability}) e o tamanho do conjunto que se pretende adicionar ao vetor (\texttt{expectedMaxSize}). 

Assumindo que a probabilidade de falsos positivos é $p$ e usando o tamanho do vetor de \textit{bytes} $n$ e o tamanho do conjunto que queremos adicionar ao filtro $m$,

$$ p =  \left[1 - \left(1 - \frac{1}{n}\right)^{km}\right]^k \approx  \left(1 - e^{-\frac{km}{n}}\right)^k $$

e

$$ a = \left(1 - \frac{1}{n}\right)^m $$

Para determinar o número $k$ ótimo de funções de \textit{hash} que devem ser utilizadas, deduz-se

$$ \ln p = k \times \ln \left(1 - a^k\right) \\
\Leftrightarrow k =  \frac{n \times \ln 2}{m}$$

A partir das fórmulas acima encontradas, conclui-se também

$$ n = \frac{m \times \ln \left(\frac{1}{p}\right)}{\left(\ln 2\right) ^ 2} $$

Para além do construtor, existem também métodos para adicionar e verificar a existência de elementos no filtro:

\begin{description}
\item[add]
Adiciona um elemento ao filtro.
\item[contains]
Verifica se o elemento passado como argumento existe no filtro (poderá haver ocorrência de falsos positivos).
\item[count]
Devolve o número de vezes que um dado elemento foi adicionado ao vetor (apenas uma estimativa).
\item[Setters]
Coleção de funções (utilizadas para testes ao módulo) que permitem a modificação dos atributos do \textit{Bloom-filter}, caso o campo \texttt{debug} (argumento opcional passado ao construtor) esteja com o valor 1.
\end{description}

Existem ainda outros métodos que não foram aqui descriminados visto ou serem privados (e portanto não relevantes à interface do módulo) ou não terem sido testados adequadamente por não terem sido necessários ao longo do trabalho.

\section{Testes}
\label{sec.bloomtests}

Para testar este módulo foram desenvolvidos diversos testes, de entre os quais uns para verificar qual seria o número ideal de funções de \textit{hash} (\texttt{k}) a utilizar, outros para verificar o tamanho ideal do vetor de \textit{bytes} (\texttt{n}), outros ainda para verificar que a família de funções de dispersão escolhida tinha um desempenho adequado.

\subsection{Distribuição de funções de \textit{hash}}
\label{subsec.hashdist}

Este módulo, \textit{test\_hashFunction\_distribution.m}, tem como principal objetivo provar que várias funções de \textit{hash} utilizadas têm uma distribuição uniforme para diversos valores de \texttt{k} (neste caso, irá variar entre 1 e 10).

Neste teste, foi gerado um conjunto de \textit{strings} aleatórias, usando a função \texttt{generateStrings}, que aceita como argumentos o tamanho do conjunto que devolverá e o tamanho máximo das \textit{strings} que irá gerar (caso o terceiro argumento seja $0$, terão tamanho fixo, caso contrário tamanho aleatório com máximo especificado pelo segundo argumento), e gerados diversos valores de \textit{hash} para cada \textit{string} e para a \texttt{seed} que estiver a ser avaliada em cada momento.

As distribuições para cada valor de \texttt{k} deverão ser o mais uniformes possíveis, de maneira a que quando utilizadas estas funções, estas não deem origem a valores concentrados numa pequena gama. Os resultados cumprem o pretendido, tal como evidenciado pelos histogramas da \autoref{fig:hashdist}.

\begin{figure}[ht]
\center
\fbox{\includegraphics[height=6cm]{img/test_HashFunction_distribution}}
\caption{Resultados das distribuições das \texttt{k} funções de \textit{hash}}
\label{fig:hashdist}
\end{figure}

\subsection{Correlação das funções de \textit{hash}}
\label{subsec.hashcorr}

Para que se possam utilizar as várias funções de \textit{hash} eficientemente (neste caso, isso significa sem aumento da taxa de falsos positivos), estas devem ser descorrelacionadas (i.e., o coeficiente de correlação respetivo deve ser 0). Neste trabalho considerar-se-ão valores de coeficiente de correlação inferiores a 0.01 como admissíveis, visto ser muito difícil que estes valores sejam verdadeiramente iguais a zero.

Este teste encontra-se no ficheiro \textit{test\_hashFunction\_correlation.m} e, tal como noutros testes, gera-se um \textit{set} de \textit{strings} aleatórias e os respetivos valores de \textit{hash} para diferentes valores de \texttt{k}, a variar entre 1 e 100. É depois criada uma matriz de dimensões \texttt{k} por \texttt{numTests} para guardar as \textit{hashes} para os diferentes pares \textit{k, string}. De seguida, calculam-se os coeficientes de correlação das funções duas a duas utilizando os resultados nas linhas da matriz anterior e a função \texttt{corrcoef} (calcula o coeficiente de correlação entre dois conjuntos, neste caso, duas linhas representativas de dois valores de \texttt{k} distintos).

Por fim, é gerado um gráfico recorrendo à função \texttt{surf} que permite ilustrar os valores de correlação resultantes. Verifica-se que para diferentes \texttt{k}s num par (i.e., comparando \texttt{k}s diferentes), os valores se situam geralmente bastante abaixo do erro admitido, havendo alguns picos onde efetivamente o coeficiente de correlação se aproxima deste valor. Conclui-se assim que as funções escolhidas são ``suficientemente'' descorrelacionadas, tal como se pretendia.

\begin{figure}[ht]
\center
\fbox{\includegraphics[height=5cm]{img/test_HashFunction_decorrelation}}
\caption{Resultados do teste de correlação de \texttt{k} funções de \textit{hash}}
\label{fig:hashcorr}
\end{figure}

\subsection{Independência das funções de \textit{hash}}
\label{subsec.hashindep}

Para além do teste de correlação, foi também efetuado um teste de independência das funções de \textit{hash} (\textit{test\_hashFunction\_independence.m}), adaptado de uma implementação disponibilizada pelo professor António Teixeira. Visto que independência implica descorrelação, este teste pode ser visto como uma versão mais forte do teste anterior. Analogamente a esse, estudou-se a independência das diferentes funções de \textit{hash} duas a duas.

Primeiramente é criado um \textit{set} de cem mil \textit{strings} aleatórias. De seguida constrói-se uma matriz \texttt{n} (número de \textit{strings} geradas) por \texttt{k} (número de funções de \textit{hash} da família \textit{FarmHash} que se pretende aplicar, neste trabalho, $k = 10$),  onde cada elemento da matriz simboliza o \textit{hash code} dum par (\textit{string}, \texttt{k}). Seguidamente, é gerado um vetor de 10 elementos (\texttt{x}) linearmente espaçados entre 0 e \texttt{N} (valor ao qual são limitados os \textit{hash codes}), e, para cada par de colunas, é criada uma matriz (\texttt{pmf}) de dimensão \verb|length(x) - 1| por \verb|length(x) - 1|. Guarda-se então em cada elemento da matriz o número de elementos das colunas de \textit{hash codes} que se situam num mesmo intervalo do vetor \texttt{x} já criado.

Por fim, é calculada a matriz de probabilidade conjunta de duas colunas (\textit{pmf - probability mass function}) dividindo cada elemento da matriz \textit{pmf} anterior pelo número de \textit{strings} que tinham sido criadas. A partir desta, são calculados os vetores de probabilidades individuais correspondentes às linhas e colunas da matriz de probabilidades conjuntas. Finalmente, é calculado o resultado da multiplicação destes dois últimos vetores e verifica-se qual a diferença entre esses valores e os registados na matriz \textit{pmf} (dois acontecimentos $A$ e $B$ são independentes se $P(A\&B) = P(A) \times P(B)$).

Como os valores da variação dos resultados são mínimos (como se observa na \autoref{fig:hashindep}, onde todos os valores se encontram na casa dos $10^{-4}$), podemos considerar que a família de funções é independente dois a dois (pelo menos até ao valor de \texttt{k} considerado), o que permite a concluir que estas funções são descorrelacionadas, tal como verificado anteriormente.

Como trabalhar a dimensões superiores (3 a 3, 4 a 4, etc.) tornaria o processo mais complexo e demorado e, usualmente, a prova de independência é feita \textit{pairwise}, 2 a 2, assume-se o resultado do teste como satisfatório.

\begin{figure}[ht]
\center
\fbox{\includegraphics[height=7cm]{img/test_hashFunction_independence}}
\caption{Resultados do teste de independência de \texttt{k} funções de \textit{hash}}
\label{fig:hashindep}
\end{figure}

\subsection{Número ideal de funções de \textit{hash}}
\label{subsec.optimalk}

O programa de teste para o valor de \texttt{k} ideal encontra-se com o nome \textit{test\_optimalK.m}.

Começa-se por se criar uma instância da classe de \textit{Bloom-filter} (módulo anteriormente desenvolvido), com o campo \texttt{debug} inicializado a 1, para que se possam utilizar as funções de atribuição de valores. Geram-se então dois conjuntos (um dos quais será adicionado ao filtro, outro não) distintos, com cem mil (valor que pode ser redefinido) \textit{strings} cada um. \textit{Strings} repetidas são removidas para que se obtenham verdadeiros \textit{sets}, e portanto o tamanho dos dois conjuntos poderá (e deverá) ser sempre ligeiramente inferior ao definido inicialmente. De seguida, define-se o tamanho do vetor de \textit{bytes} do filtro como oito vezes o tamanho do conjunto de \textit{strings} gerado que se pretende adicionar.

Por fim, itera-se sobre um vetor de \texttt{k} que se definira anteriormente (neste caso, é um vetor com valores de 1 a 15, incrementado unidade a unidade) e, para cada ciclo, define-se o \texttt{k} respetivo no objeto \textit{Bloom-filter} que está a ser utilizado. Adicionam-se então os elementos do vetor de \textit{strings} incialmente gerado e verifica-se se algum dos elementos do outro conjunto não adicionado de \textit{strings} pertence ou não ao filtro. Caso pertença, é incrementado um contador, para que, no final do ciclo, possa ser calculada a probabilidade de falsos positivos.

Utiliza-se também a fórmula

$$ p =  \left(1 - e^{-\frac{km}{n}}\right)^k $$

para determinar a probabilidade de falsos positivos (teórica) para os diferentes valores de \texttt{k} considerados. Este seria o valor utilizado por omissão.

Usando os valores do teste acima, verificamos (\autoref{fig:optimalk}) que as diferenças entre o valor teórico e o observado são mínimas, o que significa não só que é válido utilizar a expressão teórica para definir o valor de \texttt{k} na instanciação de \textit{Bloom-filters}, como também que as funções de \textit{hash} usadas devolvem excelentes resultados (o que vem de acordo com os testes anteriores). Nas condições iniciais deste teste vem que o valor de \texttt{k} ideal obtido experimentalmente é 6, o que concorda com o valor que teria sido utilizado por definição aquando da instanciação do \textit{Bloom-filter} através da dedução teórica.

\begin{figure}[ht]
\center
\fbox{\includegraphics[height=5cm]{img/test_OptimalK}}
\caption{Resultados do teste do número ideal de funções de \textit{hash} (\texttt{k})}
\label{fig:optimalk}
\end{figure}

\subsection{Tamanho ideal do vetor de \textit{bytes}}
\label{subsec.optimaln}

O módulo para o teste do valor ideal do tamanho \texttt{n} do vetor encontra-se no ficheiro \textit{test\_optimalN.m}.

Tal como no teste da \autoref{subsec.optimalk}, também são criados dois conjuntos de \textit{strings} aleatórias com o mesmo propósito, um para ser adicionado ao filtro e o outro não. É também criado um vetor com diferentes valores de \texttt{n}, que vão desde o tamanho do conjunto de \textit{strings} a adicionar até 10 vezes esse valor, com um incremento de metade do tamanho do conjunto entre cada.

De seguida, itera-se sobre os valores deste último vetor, criando-se uma instância de um \textit{Bloom-filter} com os valores de \texttt{n} (atributo \texttt{arraySize} do módulo) e \texttt{k} (que depende do tamanho do vetor) a cada passagem. Adiciona-se um dos conjuntos de \textit{strings}, verifica-se a existência dos elementos do outro que não foi adicionado e, por fim, calcula-se a probabilidade de falsos positivos, de maneira semelhante ao que foi feito no teste anterior. Vai sendo também calculado, para cada valor de \texttt{n}, o valor teórico correspondente da probabilidade de falsos positivos e guardando estes valores num segundo vetor.

Como se verifica no gráfico da \autoref{fig:optimalnimg}, à medida que o tamanho do \textit{array} aumenta, a probabilidade de falsos positivos diminui, i.e., são inversamente proporcionais, o que já era esperado visto que com um vetor maior haverá mais espaço para os possíveis \textit{hash codes} gerados pela função de \textit{hash}. No entanto, o mais importante com este teste é verificar que os valores experimentais são semelhantes aos teóricos, já que o importante será para um dado valor de erro admissível, dimensionar o \textit{array} interno eficientemente (pois caso contrário ou se vai ocupar memória desnecessária, ou o número de falsos positivos real será acima do admissível). Como os valores obtidos (experimentais e teóricos) são bastante semelhantes, conclui-se que a dedução teórica que é utilizada no construtor do filtro permite um bom dimensionamento da estrutura de dados interna deste.

\begin{figure}[ht]
\center
\fbox{\includegraphics[height=5cm]{img/test_OptimalN_img}}
\caption{Resultados do teste do tamanho ideal do vetor de \textit{bytes} (\texttt{arraySize} ou \texttt{n})}
\label{fig:optimalnimg}
\end{figure}

Os valores ideias são os presentes na \autoref{fig:optimalntext}.

\begin{figure}[ht]
\center
\fbox{\includegraphics[height=5cm]{img/test_OptimalN_txt}}
\caption{Resultados ideias do tamanho ideal do vetor de \textit{bytes} (\texttt{arraySize} ou \texttt{n})}
\label{fig:optimalntext}
\end{figure}

\subsection{Testes práticos do \textit{Bloom-filter}}
\label{subsec.testebloom}

Foram desenvolvidos dois módulos semelhantes para testes mais direcionados ao uso real de um \textit{Bloom-filter}. Estão em dois ficheiros distintos, \textit{test\_big\_BloomFilter.m} e \textit{test\_small\_BloomFilter.m}.

O primeiro (\textit{big}) segue o modelo dos testes anteriores, em que se geram dois \textit{sets} de um certo tamanho (neste caso, cem mil elementos) de \textit{strings} aleatórias, cria-se uma instância de um \textit{Bloom-filter} com uma probabilidade de falsos positivos de 0.0001\%, adiciona-se um dos conjuntos ao filtro e verifica-se a ocorrência de falsos positivos com o outro. Por fim, compara-se o resultado observado da probabilidade de falsos positivos com a que se definiu aquando a criação do filtro. O objetivo é que os resultados sejam o mais próximos possíveis.

No segundo teste (\textit{small}), contrariamente ao primeiro em que se geram os conjuntos, definem-se conjuntos muito pequenos inicialmente e, depois, executa-se o mesmo processo que anteriormente.

\begin{figure}[ht]
\center
\fbox{\includegraphics[height=5cm]{img/test_big_BloomFilter}}
\caption{Resultados da execução de \textit{test\_big\_BloomFilter.m}}
\label{fig:testbigbloom}
\end{figure}

\chapter{Locality-sensitive hashing}
\label{chap.lsh}

\textit{Locality-sensitive hashing (LSH)} é particularmente útil quando se têm, por exemplo, grandes conjuntos de documentos e se pretende encontrar aqueles semelhantes entre si, como, por exemplo, encontrar notícias semelhantes (em conteúdo) em diversos \textit{websites}. Muitas das vezes, com conjuntos com tamanho na ordem dos milhões, são tantas as comparações necessárias a fazer e a memória necessária para guardar os documentos, que se torna inviável a utilização de métodos ``clássicos'', por exemplo, comparando os documentos no seu todo um a um.

Com o objetivo de implementar um módulo capaz de efetuar a procura pelos vizinhos mais próximos (\textit{nearest neighbor search}), guardando representações de documentos mais facilmente comparáveis e que ocupam geralmente menos espaço, seguiram-se três passos:

\begin{description}
\item[Shingling]
Converter documentos para conjuntos de elementos (habitualmente pequenas \textit{strings}) denominados \textit{shingles}, o que permite uma melhor representação do conteúdo de um documento. Neste trabalho escolheu-se uma técnica de extração de \textit{shingles} sugerida em \cite{book1}, onde se procura por \textit{stopping words} e, para cada palavra encontrada, forma-se um \textit{shingle} constituído pela palavra encontrada e pelas duas seguintes.
\item[Minhashing]
Converter grandes conjuntos (usualmente de \textit{shingles}) para uma pequena assinatura (por norma, vetor de \textit{hash codes}), preservando o conceito de similariedade entre diferentes documentos (neste caso, conjuntos de \textit{shingles}).
\item[Locality-sensitive hashing]
Reduzir o conjunto de elementos a candidatos de forma eficiente, testando mais tarde a sua ``real'' similariedade.
\end{description}

O módulo de \textit{LSH} está escrito no ficheiro \textit{LSH.m} e dispõe dos seguintes métodos:

\begin{description}
\item[shingleWords]
Aceita um \textit{cell array} com as palavras (\textit{strings}) que constituem um documento e devolve um conjunto de \textit{shingles} relativos ao mesmo, construído tendo em conta um conjunto de \textit{stopping words}.
\item[signature]
Converte um conjunto (mais precisamente \textit{cell array}) de \textit{shingles} numa assinatura (vetor de inteiros), recorrendo a um processo de \textit{minhashing}.
\item[candidates]
Devolve a lista de documentos candidatos a formarem conjuntos semelhantes, consoante a matriz de assinaturas e o \textit{threshold} passados como argumentos.
\item[candidates\_to]
Executa um processo semelhante ao da função \texttt{candidates}, no entanto em vez de formar conjuntos de candidatos para uma dada matriz de assinaturas, forma uma lista de candidatos (representados numa matriz de assinaturas), face a um documento específico (representado pela sua assinatura e passada como argumento).
\item[similars]
Verifica quais são os documentos de um conjunto de candidatos realmente semelhantes, consoante a matriz de candidatos, assinaturas e o \textit{threshold} passados como argumentos. Esta comparação é feita utilizando as assinaturas dos documentos.
\item[similiars\_to]
Semelhante à função \texttt{similars}, no entanto, aplica-se ao caso em que pretendemos comparar os candidatos a similares entre um único documento e outro conjunto de documentos (sendo os documentos tal como habitualmente representados pelas suas assinaturas).
\end{description}

O construtor do módulo aceita apenas um argumento (\texttt{expectedError}), que é o erro esperado quando se calcula a similaridade entre dois conjuntos representados pelas suas assinaturas, obtidas segundo o método de \textit{Minhash}, face à real similaridade de Jaccard entre esses conjuntos. Este valor é utilizado para calcular o tamanho \texttt{k} das assinaturas (e, portanto, o número de funções de dispersão necessárias). \texttt{k} é o único atributo que o módulo possui (não considerando o atributo \texttt{debug}, utilizado em \textit{debugging}), e é calculado utilizando a fórmula

$$ k = \frac{1}{expectedError^2} $$

Este resultado é obtido pelos limites de Chernoff (\textit{\href{https://en.wikipedia.org/wiki/Chernoff\_bound}{Chernoff bounds}}), concluindo-se que o erro esperado para o cálculo da similaridade de dois conjuntos segundo o método de \textit{Minhash} é $\mathcal{O}\left(\frac{1}{\sqrt{k}}\right)$.

\subsection{Shingling}
\label{subsec.shingling}

Um \textit{k-shingle} de um documento é uma sequência de \textit{k tokens} (palavras, caracteres, etc.) que aparecem no documento. Documentos que tenham muitas \textit{shingles} em comum possuem texto parecido, mesmo que este não apareça na mesma ordem. Este facto é importante pois permite determinar a semelhança entre diferentes documentos tendo em conta a ordem segundo a qual diferentes palavras aparecem (considere-se que facilmente se escrevem dois textos com aproximadamente as mesmas palavras, mas em que, dada a ordem com que estas aparecem, o conteúdo destes documentos é bastante diferente).

A similariedade entre dois documentos ($D1, D2$) pode ser calculada através da similariedade de Jaccard:

$$ sim(D1, D2) = \frac{|C1\cap C2|}{|C1\cup C2|} $$

sendo $C1$ e $C2$ os conjuntos de \textit{shingles} de $D1$ e $D2$, respetivamente.

A distância de Jaccard, por outro lado, pode ser dada por:

$$ d(D1, D2) = 1 - sim(D1, D2) $$

Para gerar um \textit{set} de \textit{shingles} é utilizada a função \texttt{shingleWords} do módulo escrito, que recebe como argumento um \textit{cell array}, neste caso, de \textit{strings} que contêm as palavras do documento (considere-se \texttt{Doc}) para o qual se quer gerar o conjunto de \textit{shingles}. Para gerar esse conjunto, é necessário selecionar quais as sequências de palavras mais importantes de \texttt{Doc}. Para tal, e seguindo o algoritmo sugerido em \cite{book1}, é necessária a criação de um \textit{set} de \textit{stop words}. Estas palavras devem ser palavras que apareçam com grande frequência na língua considerada e que geralmente aparecem próximas de palavras importantes no contexto de um documento. Assim, e para este efeito, foram guardadas num \textit{cell array} as cem palavras mais comuns da língua inglesa. Quando o programa encontra uma \textit{stopping word}, guarda a sequência \textit{stop\_word next\_word1 next\_word2} num segundo \textit{cell array}, que será o retorno da função.

\subsection{Minhashing}
\label{subsec.minhash}

Para contornar as demoras que as comparações de excertos de textos provocariam e a memória eventualmente necessária para os ter em RAM, os \textit{shingles} são convertidos em assinaturas (vetores de inteiros). No entanto, a similariedade entre documentos deve manifestar-se também nestas assinaturas. Para isto utilizou-se uma técnica de \textit{MinHash}, \textit{Many Hash}, que consiste em considerar \textit{k hash functions} (\textit{k} será também o tamanho da assiantura). Para cada \textit{i} entre 1 e \texttt{k}, calcular $\text{hash}_i$ de todos os elementos do conjunto para o qual está a ser gerada a assiantura. O elemento \textit{i} da assinatura será o mínimo de todos os $\text{hash}_i$ gerados anteriormente.

Com este objetivo foi criada a função \texttt{signature}. Inicialmente é criado um vetor de tamanho \texttt{k}, tal como definido no construtor do módulo. De seguida, para cada \textit{seed} entre 1 e \texttt{k} é gerado um vetor de \textit{hash codes} para o \textit{cell array} de \textit{shingles} passado como argumento, e para esse valor de \textit{seed}. É depois calculado o mínimo desse vetor, guardando-se o resultado na posição \textit{seed} do vetor assinatura que será no final devolvido pela função.

\subsection{Locality-sensitive hashing}
\label{subsec.lsh}

Por fim, depois de geradas as assinaturas dos documentos, estas podem ser comparadas para se determinar os documentos que mais se assemelham.

Para isso, inicialmente começa-se por se definir uma lista de candidatos possíveis (onde é ``provável'' a ocorrência de falsos positivos), para, mais tarde, se verificar quais aqueles que são realmente semelhantes. É por isso necessário definir um valor de \textit{threshold}, que deverá indicar quão semelhantes dois documentos devem ser para poderem ser considerados similares, no contexto do problema considerado.

A função \texttt{candidates} definida no módulo \texttt{LSH} serve para calcular a lista de candidatos possíveis.

Consideremos a matriz de assinaturas \textit{S}, onde cada coluna corresponde à assinatura de um documento (i.e., o resultado do processo de \textit{minhashing} dos \textit{shingles} obtidos para esse documento).

Esta matriz é dividida em \texttt{b} bandas (\textit{bands}) de \texttt{r} linhas (\textit{rows}) cada. Então, para cada banda verificam-se quais as colunas (da banda) iguais - estes elementos serão considerados candidatos e serão, portanto, adicionados ao \textit{cell array} de candidados que será devolvido.

Tendo em conta que

$$ br = k,\ k\ \text{tamanho de cada assinatura} $$

e

$$ t \approx \left(\frac{1}{b}\right) ^ {\frac{1}{r}} $$

onde $t$ é o \textit{threshold} escolhido, pode aproximar-se \texttt{b} ou \texttt{r} e em função do valor calculado, obter o outro.

A estrutura da matriz de retorno (\textit{cell array} de candidatos) é tal que cada linha \textit{i} corresponde ao documento \textit{i} e cada elemento dessa linha corresponde ao documento \textit{j}, significando que esse par \textit{(Docs{i}, Docs{j})} constitui um par de candidatos (ou seja, o documento \textit{i} poderá ser semelhante ao documento \textit{j}). \textit{i} e \textit{j} são os índices da matriz de assianturas recebida como argumento para os quais foi detetada alguma semelhança.

No final da execução da função, deverá obter-se um \textit{cell array} com todos os pares de candidatos a serem semelhantes. É de notar que, na abordagem seguida, tenta-se eliminar entradas irrelevantes, ou seja, se a matriz de candidatos indica que poderá haver semelhança entre \textit{Docs{i}} e \textit{Docs{j}}, então não deverá indicar o equivalente \textit{Docs{j}} ``semelhante a'' \textit{Docs{i}}.

Por fim, a função \texttt{similars} trata de finalizar o processo e devolver os pares de documentos que são realmente semelhantes, incluindo o respetivo coeficiente de similariedade.

Para isso, itera-se sobre a matriz de candidatos e compara-se, um a um, se a similariedade de Jaccard entre as assinaturas é maior ou igual ao \textit{threshold} definido (usando a função \texttt{intersect}, que devolve os elementos em comum entre dois conjuntos). Se a condição se verificar, adiciona-se ao vetor de retorno os índices na matriz de assinaturas dos documentos em questão e o valor da sua similariedade, segundo um modelo \textit{DocN  DocZ  sim(DocN, DocZ)}.

\subsection{Testes}
\label{subsec.lshtests}

Para os testes deste módulo, foram adaptados os \textit{scripts} do Guião Prático-Laboratorial 07 da disciplina, mas, para além de ser usado o \textit{dataset} de cem mil utilizadores da MovieLens, foi também utilizado o que contém um milhão de utilizadores.

A única diferença entre os testes é apenas o \textit{dataset} utilizado, pois o processo tem obrigatoriamente de ser o mesmo, apenas variando o tamanho do conjunto de dados.

Inicia-se o teste obtendo um vetor com todos os utilizadores a partir do \textit{dataset}. De seguida, para cada utilizador, constrói-se o conjunto de \textit{shingles}. Neste caso não é usada a função \texttt{shingleWords} do módulo \texttt{LSH} dado que cada conjunto de filmes define por si só cada utilizador. Após terem sido construídos estes vetores, os seus elementos são convertidos para \textit{strings} para que possam ser utilizados diretamente pela função encarregue de gerar assinaturas de conjuntos, sendo este passo realizado utilizando a função \texttt{signature}. 

Inicialmente é calculada a similariedade de Jaccard esperada (teórica), simplesmente iterando sobre o conjunto de assinaturas e utilizando a expressão 

$$ sim(D1, D2) = \frac{|C1\cap C2|}{|C1\cup C2|} $$

e as funções de MATLAB \texttt{intersect} (devolve os elementos que dois conjuntos têm em comum) e \texttt{union} (devolve a união de dois conjuntos) (é ainda utilizada a função \texttt{length} pois apenas importa o tamanho dos conjuntos que as duas funções anteriores retornam). Por fim, verifica-se quais destes valores acima do \textit{threshold} definido (nestes testes, este valor foi de 0.6). Os resultados mostram que existem apenas 3 documentos com similariedade acima dos 0.6, como se verifica na \autoref{fig:test100ke}.

\begin{figure}[ht]
\center
\fbox{\includegraphics[height=2cm]{img/test_LSH_100k_Exp}}
\caption{Resultados (valores esperados) do teste com 100 mil utilizadores}
\label{fig:test100ke}
\end{figure}

Finalmente, para calcular a similariedade observada (experimental), gera-se a lista de candidatos usando a função \texttt{candidates} do módulo \texttt{LSH} e a matriz com os documentos similares usando a função \texttt{similars}, também do mesmo módulo.

A \autoref{fig:test100ko} mostra que os resultados de ambos os testes foram os mesmos, havendo apenas uma pequena variação dos valores de similariedade (à volta de 0.02). Note-se que a instância de \textit{LSH} utilizada foi inicializada para um erro de 0.05, e portanto como $0.02 < 0.05$ os resultados estão de acordo com o esperado e dentro dos limites admissíveis.

\begin{figure}[ht]
\center
\fbox{\includegraphics[height=2cm]{img/test_LSH_100k_Obs}}
\caption{Resultados (valores observados) do teste com 100 mil utilizadores}
\label{fig:test100ko}
\end{figure}

No teste com um milhão de utilizadores, usou-se também um \textit{threshold} de 0.6, no entanto, na construção da matriz de candidatos (utilizando a função \texttt{candidates}), utilizou-se um valor de 0.55, com o objetivo de ``apanhar'' valores muito próximos do limiar considerado, já que foi definido um erro admissível de 0.05.

Depois de observados os resultados do teste (\autoref{fig:test1mo}), verificamos que estes são bastante satisfatórios e de acordo com o esperado. Devido ao erro assumido de 0.05, alguns resultados muito próximos do limiar podem ou não ser apresentados. Como verificamos na \autoref{fig:test1mo}, a similariedade de duas assinaturas de listas de filmes de utilizadores é muito próxima do limiar definido (0.6), no entanto visto ser inferior a este não foi incluida na lista de pares similares calculada. O valor teórico para a similaridade deste par de utilizadores é na verdade 0.6012 (quando consideradas as listas de filmes de cada um, e não as suas assinaturas), e portanto este par deveria ter sido dado como par similar. Ainda assim, é um resultado mais uma vez admissível visto ter-se utilizado um erro de 0.05 para a precisão do cálculo da similaridade de dois elementos através do uso das suas assinaturas.

\begin{figure}[ht]
\center
\fbox{\includegraphics[height=8cm]{img/test_LSH_1m_Obs}}
\caption{Resultados (valores observados) do teste com 1 milhão de utilizadores}
\label{fig:test1mo}
\end{figure}

\chapter{SPAM Filter}
\label{chap.spamfilter}

A filtragem de \textit{email} é uma maneira de o organizar segundo um dado critério, por exemplo detetando \textit{spam} evitando assim ter de ler mensagens sem interesse. Neste trabalho, considera-se \textit{spam} como sendo mensagens que, para um dado utilizador, não têm interesse (ou seja, o que é \textit{spam} para uma pessoa poderá não o ser para outra), e portanto poderá ser visto como apenas mais uma forma de categorizar \textit{emails}.

Esta funcionalidade é geralmente oferecida por empresas como a Google ou Microsoft, que habitualmente utilizam algoritmos que detetam, por exemplo, picos de atividade de determinados endereços (especialmente se até então desconhecidos), bem como \textit{feedback} dos seus utilizadores que marcam ou não como \textit{spam} os \textit{emails} que recebem. A par disto, muitas vezes as mensagens que levantam mais dúvidas são verificadas por equipas com essa tarefa.

Outra forma de filtrar \textit{spam} de uma caixa de entrada poderá ser comparar o conteúdo de \textit{emails} previamente consideramos como tal e ver se são semelhantes à mensagem que se acabou de receber - se sim, colocar a mensagem na pasta certa (que pode ser diretamente o caixote do lixo), se não, então nada fazer. Outro método é verificar se o endereço de \textit{email} da nova mensagem já enviara algum \textit{email} de \textit{spam} anteriormente.

Neste trabalho pretende-se implementar um simples filtro de \textit{spam} (ou qualquer outro tipo de mensagens) de acordo com o exposto no último paragrafo, utilizando para isso um \textit{Bloom-filter} (de forma a filtrar facilmente por endereço) e técnicas de \textit{Locality-sensitive hashing} (para se filtrar por conteúdo).

O \textit{Bloom-filter} servirá como armazenamento de endereços de \textit{email} que previamente tinham enviado lixo, constituindo assim uma \textit{blacklist} de mensagens que deverão ser imediatamente filtradas. Já \textit{Locality-sensitive hashing} servirá para comparar o conteúdo de novas mensagens com antigas mensagens marcadas como \textit{spam}, permitindo assim inferir novas mensagens como sendo de interesse ou não. Algumas das principais vantagens desta abordagem são a facilidade da sua implementação, bem como a eficiência de filtragem que demonstra não só em termos de velocidade de execução, mas também permitindo, por exemplo, que cada utilizador tenha a sua própria lista de \textit{emails} sem interesse. Visto ser um modelo que utiliza técnicas probabilísticas, deverá também ser altamente escalável.

Os passos necessários para a filtragem segundo este modelo serão:

\begin{description}
\item[Aprendizagem] \hfill \\
  Esta fase deverá ser executada uma vez. Aqui o programa deve aprender a que se assemelha \textit{spam}, permitindo mais tarde filtrar mensagens semelhantes. Para isso, deverão ser fornecidos ao programa \textit{emails} considerados como \textit{spam}, e o programa em troca deve não só armazenar os remetentes destas mensagens num \textit{Bloom-filter} para referência futura, como também gerar e guardar uma assinatura segundo a técnica de \textit{Minhash} para o corpo da mensagem. Este último passo é executado conforme indicado anteriormente no que toca à criação de um conjunto de \textit{shingles} para um documento, bem como à posterior geração da assinatura desse conjunto. Estas assinaturas vão sendo guardadas numa matriz onde cada coluna é referente à assinatura de um \textit{email} de \textit{spam}.
\item[Verificação 1] \hfill \\
  Neste momento, o modelo utilizado já conhece o que é \textit{spam}, e portanto está apto a filtrar este tipo de mensagens. Nesta primeira fase de filtragem, deverá ser verificado se o endereço do remetente é ou não um endereço \textit{blacklisted}. Note-se que, visto que o \textit{Bloom-filter} deste trabalho foi implementado como um \textit{Counting filter}, poderá ser mais proveitoso não apenas verificar se um endereço pertence ou não ao filtro, mas antes verificar se a contagem para esse endereço é superior a um determinado valor. Neste sentido foi assumido que um remetente tem de enviar pelo menos dois \textit{emails} considerados \textit{spam} para o seu endereço ser filtrado.
\item[Verificação 2] \hfill \\
  Caso a mensagem passe na verificação acima, então passa-se a uma fase onde o conteúdo da mensagem é analisado contra o conhecimento que o modelo tem do que é \textit{spam}. Também esta verificação é dividida em vários passos:
  \begin{enumerate}
  \item Começa-se por se gerar o conjunto de \textit{shingles} referentes ao \textit{email}. Caso este forme um conjunto vazio, então imediatamente conclui-se que a mensagem é \textit{spam}, já que nenhuma informação relevante foi obtida. Caso contrário, calcula-se a assinatura do \textit{email} e avança-se para a fase seguinte. \\
    A construção do conjunto de \textit{shingles} e da assinatura do \textit{email} é conforme o já referido anteriormente.
  \item Conhecendo a assinatura da mensagem e possuindo a matriz de assinaturas de \textit{emails} de \textit{spam}, calcula-se a lista de candidatos da matriz de assinaturas a serem semelhantes à assinatura da mensagem a avaliar atualmente. Isto é possível recorrendo ao método \texttt{candidates\_to} do módulo \textit{LSH}, que funciona tal como a função homóloga \texttt{candidates}, com a diferença de que a primeira calcula os candidatos face a um determinado documento (e não todos os conjuntos de candidatos possíveis como a segunda). \\
    Caso seja retornado um conjunto vazio, então conclui-se que a mensagem atual não se assemelha a \textit{spam} e portanto a verificação termina indicando que a mensagem é de interesse. Caso contrário, avança-se para a fase seguinte.
  \item Por fim, a partir da lista de candidatos gerada na fase anterior, calculam-se as verdadeiras semelhanças entre as diferentes assinaturas dos candidatos, a partir da função \texttt{similars\_to} que faz as vezes da função \texttt{similars}, com a diferença de que a primeira é também específica para calcular assinaturas similares a uma só assinatura, ou contrário da segunda que calcula os pares similares para todos os elementos da matriz de candidatos. Caso seja devolvida uma matriz vazia, o passo anterior apenas devolveu falsos positivos e portanto a mensagem não é considerada \textit{spam}. Caso contrário, o conteúdo da mensagem assemelhou-se a algum outro doutra mensagem que tinha sido aprendida (como \textit{spam}), e portanto conclui-se que esta deve também ser uma mensagem sem interesse.
  \end{enumerate}
\end{description}

Note-se que nos dois pontos da descrição anterior, as duas funções utilizadas utilizam um valor de \textit{threshold}, passado como argumento, que deve ser definido tendo em conta dois fatores: um valor muito elevado garantirá que muito poucas mensagens que não são \textit{spam} sejam detetadas como tal, por outro lado, poderá estar-se a não filtrar mais mensagens que são efetivamente \textit{spam}. O contrário acontece para valores muito baixos de \textit{threshold}, onde quase todos os \textit{emails} de \textit{spam} serão filtrados, mas também mais mensagens com interesse podem ser filtradas.

Assim, primeiro é necessário que o programa ``aprenda'' que \textit{emails} deve filtrar. Para tal, foi utilizado um \textit{dataset} do grupo \textit{Enron}\footnote{\url{http://csmining.org/index.php/enron-spam-datasets.html}}. A função \texttt{create\_generic} permite a aprendizagem, aceitando um diretório onde vai procurar pelos ficheiros da extensão que também lhe é passada como argumento, para guardar num ficheiro (o caminho também é passado como argumento) as estruturas \textit{Bloom-filter} com os endereços de \textit{email} que enviaram \textit{spam} adicionados, as assinaturas do conteúdo dos mesmos e o módulo de \textit{LSH} usado (para salvaguardar o número de funções de \textit{hash} utilizadas).

Por outro lado, a função \texttt{test\_generic} testa o filtro de \textit{spam} com base no ficheiro previamente guardado. Os dados desse mesmo ficheiro são carregados para o programa e todos os \textit{emails} contidos na pasta que lhe é passada como argumento são analisados.

É de notar que o método descrito acima para filtragem de \textit{spam} pode ser facilmente utilizado para filtrar por tema, permitindo, por exemplo, categorizar \textit{emails} com três \textit{labels}, \textit{Primary}, \textit{Social} e \textit{Promotions} à semelhança do que o \textit{Gmail} da Google faz. Basta para isso fornecer um conjunto de aprendizagem adequado. O programa pode também aprender com a experiência a melhorar os seus resultados, bastando para isso que, quando falha a filtragem de uma mensagem e o utilizador o assinale, seja adicionado o endereço do remetente ao filtro de \textit{Bloom} em uso e a assinatura da mensagem à matriz de assinaturas que já possui.

\section{Teste}

O teste levados a cabo nesta fase foi o meno claro de todo o projeto, dada a falta de dados para testar eficientemente o programa.

Para este teste foi utilizado o \textit{dataset} do grupo \textit{Enron}, que continha cerca de 17 mil \textit{emails} de \textit{spam} e 16 mil \textit{non-spam} (\textit{ham}). Antes de se executarem os testes, deve-se correr o programa de aprendizagem da aplicação para este \textit{dataset} (\textit{enron\_training.m}).

No ficheiro \textit{test\_thresold.m} foram executados vários testes de deteção de \textit{spam} para diferentes valores de \textit{threshold} (entre 0.1 e 1, com espaçamento de 0.1 entre eles). Conclui-se que o melhor compromisso entre falsos positivos e falsos negativos é para um valor de \textit{threshold} de 0.1, o que assegura uma taxa de deteção de \textit{spam} de 83\% e uma de deteção de \textit{non-spam} (portanto falsos positivos) de 3\%, dos quais mais de 2\% se devem a mensagens a partir das quais não foi possível formar quaisquer \textit{shingles}.

O teste realizado com o valor de \textit{threshold} encontrado no teste anterior encontra-se no ficheiro \textit{test\_enron.m} que, consoante os resultados obtidos da aprendizagem, chama a função \texttt{test\_generic} que devolverá as mensagens consideradas como \textit{spam} e o número de \textit{emails} analisados. Os resultados são os da \autoref{fig:enronspam} e da \autoref{fig:enronnonspam}.

\begin{figure}[ht]
\center
\fbox{\includegraphics[height=3cm]{img/test_enron_spam}}
\caption{Resultados do teste ao \textit{dataset} do grupo \textit{Enron}, fornecendo apenas mensagens de \textit{spam}}
\label{fig:enronspam}
\end{figure}

Os resultados da análise a \textit{emails} com \textit{spam} resultou numa percentagem de deteção de ``lixo eletrónico'' de cerca de 83\%, o que se pode explicar por se ter tido de separar o \textit{dataset} em dois conjuntos (um para aprendizagem e outro para testes); isto leva a que a base de aprendizagem não seja tão grande e que alguns dos \textit{emails} com conteúdo de \textit{spam} não sejam detetados.

\begin{figure}[ht]
\center
\fbox{\includegraphics[height=7cm]{img/test_enron_no_spam}}
\caption{Resultados do teste ao \textit{dataset} do grupo \textit{Enron}, fornecendo apenas mensagens de \textit{non-spam}}
\label{fig:enronnonspam}
\end{figure}

Os resultados da filtragem de \textit{emails} \textit{ham} resultaram numa deteção de 3\% de \textit{spam}. No entanto, como se verifica, em apenas uma das mensagens o programa conseguiu gerar \textit{shingles} (depois de analisar esta mensagem em concreto, concluiu-se que efetivamente esta se assemelhava a \textit{spam}). As restantes foram consideradas ``lixo'' pois não foi possível gerar \textit{shingles} das mesmas, provavelmente porque se tratavam de \textit{emails} com agradecimentos ou pequenas expressões, como por exemplo, ``Ok'', ``Thank you'', ``Done'' como foi verificado após algumas das mensagens terem sido verificadas à mão.

\section{Programa \textit{demo}}

Foi desenvolvido ainda um programa \textit{demo} (\textit{proof\_of\_concept.m}) que pretende funcionar como \textit{proof of concept} do modelo de filtragem apresentado. Para isso, foram testados \textit{emails} sem interesse que recorrentemente são recebidos pelos autores deste projeto. Com um \textit{use case} específico pretende-se mostrar como funciona efetivamente o programa.

Assim, começou-se por se juntar um conjunto de cerca de 40 \textit{emails} que são, por nós, considerados como lixo. No entanto, são mensagens de fontes fidedignas e possivelmente com interesse para outras pessoas e, portanto, não são filtradas por definição por serviços de \textit{email} como o \textit{Gmail}. Guardou-se depois um pequeno número de \textit{emails} que são consideradas com interesse e verificou-se se alguma destas mensagens era filtrada como \textit{spam} pelo programa (dando origem a um falso positivo). Posto isto e para efeitos demonstrativos, o programa entra num \textit{loop} onde permite a verificação de outras mensagens sem que estas tenham de ser previamente pré-processadas. O resultado é o ilustrado na \autoref{fig:poc1}.

\begin{figure}[ht]
\center
\fbox{\includegraphics[height=7cm]{img/proof_of_concept1}}
\caption{Resultados da execução do programa \textit{demo} + janela para teste de novos \textit{emails}}
\label{fig:poc1}
\end{figure}

Neste teste conseguiu-se filtrar as mensagens sem interesse, ao mesmo tempo que as relevantes não eram afetadas.

\chapter{Conclusões}
\label{chap.conclusões}

Tendo em conta a eficiência demonstrada por filtros de \textit{Bloom}, conclui-se que estes são efetivamente ótimas estruturas quando se pretende confirmar a existência de um elemento num conjunto muito grande e se admite um pequeno erro (de falsos positivos); por outro lado, e face aos resultados que apresenta, \textit{Locality-sensitive hashing} (aliado a técnicas de \textit{shingling} e \textit{minhashing}) poderá ser uma ótima solução em algoritmos de \textit{nearest-neighbour search} e \textit{clustering}. Estas conclusões são baseados nos resultados bastante satisfatórios de testes relativos ao módulo de \textit{Bloom-filter} e de \textit{Locality-sensitive hashing}, resultando em desvios mínimos em relação aos valores teóricos.

Juntando estes dois métodos, foi possível criar um filtro de \textit{spam} (ou de outros conteúdos) em que se obtiveram resultados satisfatórios tendo em conta os \textit{datasets} utilizados.

Por fim, é de notar que qualquer modelo probabilístico é isso mesmo, apenas probabilístico, e assim sendo por mais eficiente que um filtro de \textit{Bloom}, por exemplo, possa ser, só faz sentido ser utilizado em situações onde é admissível cometer algum erro. Isto pode ser um factor limitante em algumas situações, por outro lado, e sendo o mundo um lugar probabilístico a, vasta maioria dos casos monstra-nos que é possível trabalhar com alguma margem para erro, desde que esta seja suficientemente pequena. Assim, adotar aproximações probabilísticas a vários problemas pode contribuir para dar origem a soluções não só mais eficientes como até mais simples. E com o crescente aumento da informação disponível no mundo, cada vez mais soluções destas deverão ser precisas.

\maketitle
\nocite{*}

\printbibliography[title={Referências}]

\end{document}
