\documentclass[a4paper,11pt,openright,oneside]{report}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[portuguese]{babel}
\usepackage{graphicx}
\usepackage[backend=biber, style=ieee]{biblatex}
\usepackage{csquotes}
\usepackage{blindtext}
\usepackage[printonlyused]{acronym}
\usepackage{hyperref}
\usepackage{indentfirst}
\usepackage[titletoc,title]{appendix}
\usepackage{mathtools}
\usepackage{amsmath,amsthm,amsfonts,amssymb}
\usepackage{caption}
\usepackage{subcaption}
\newcommand{\RNum}[1]{\uppercase\expandafter{\romannumeral #1\relax}}

\bibliography{report.bib}

\begin{document}

\begin{titlepage}
\begin{center}

{\vspace*{50mm}\textsc{\Huge\textbf{Bloom-filter + Locality-Sensitive Hashing}\\ \small{Métodos Probabilísticos para Engenharia Informática}}}\\[2cm]
{\textsc{\small\textbf{Universidade de Aveiro}}}\\[0.5cm]
{\small Pedro Martins 76551\\Ricardo Jesus 76613}\\[0.5cm]
{\small	17 de Dezembro de 2015}\\

\begin{figure}[b]
\center
\graphicspath{}
\includegraphics[height=2cm]{ua.pdf}
\end{figure}

\end{center}

\end{titlepage}

\title{\textbf{Bloom-filter + Locality-Sensitive Hashing}\\[1cm]\textsc{\small {Departamento de Electrónica, Telecomunicações e Informática} \\ \large {UNIVERSIDADE DE AVEIRO}}}
\author{Pedro Martins 76551, pbmartins@ua.pt\\Ricardo Jesus 76613, ricardojesus@ua.pt}
\date{17 de Dezembro de 2015}

\maketitle

\pagenumbering{roman}

\begin{abstract}

ABSTRACT

\end{abstract}

\tableofcontents
%\listoftables
\listoffigures

\clearpage
\pagenumbering{arabic}

\chapter{Introdução}
\label{chap.introdução}

Na área da informática, muitas vezes é necessário saber se algo pertence a conjunto de forma eficiente. Em muitas linguagens de programação, a maneira mais comum seria percorrer todo o conjunto e comparar, um a um, todos os elementos até encontrar o que se inicialmente andava à procura. No entanto, este método é deveras ineficiente, principalmente se se estiver a trabalhar com conjuntos com milhões ou mais elementos, e aí que surgem os \textit{Bloom-filters}. 

Este filtros usam uma ou várias funções de \textit{hashing} para determinar a pertença de um elemento no \textit{set}. São muito utilizados em grandes conjuntos de dados e em diversas aplicações como o corretor ortográfico dos computadores, \textit{smartphones}, etc., análise textual, entre outras. Contudo, é um método probabilístico com um valor de erro associado.

Neste trabalho, foi desenvolvido em Matlab um \textit{Bloom-filter} e desenhada uma interface para um função de \textit{hashing} desenhada em C++ para atingir este objetivo.

\chapter{Bloom-filter}
\label{chap.bloom}

Os \textit{Bloom-filters} usam uma ou várias funções de \textit{hashing} para determinar a pertença de um elemento no \textit{set}. Deste modo, mesmo que se opere sobre um conjunto com milhões ou milhares de milhões de elementos, será sempre um processo muito mais eficiente do que se se iterasse sobre todo o \textit{set} à procura do elemento em questão (dependendo também do número e da qualidade das funções de \textit{hashing} utilizadas).

No entanto, é um método probabilístico, e tem um erro associado. Na criação de um \textit{Bloom-filter} define-se sempre um erro máximo esperado, erro esse que apenas ocorre na "inclusão", isto é, um membro que à partida já se saiba que pertença ao conjunto nunca será considerado não pertencente, mas alguns membros que, à partida, se saiba que não estão no \textit{set}, podem ser considerados como pertencentes ao conjunto.

Para diminuir esse erro, por norma, para além de aumentar o tamanho do \textit{set}, usa-se um número variado de funções de \textit{hashing} descorrelacionadas entre si, em vez de utilizar apenas uma. Isto permite que os resultados do \textit{hashing} estejam mais dispersos por todo o vetor. Neste caso, em vez de utilizarmos k funções diferentes, utilizaremos a família de funções \textit{FarmHash}, desenvolvida pela Google, em que um dos argumentos, a \texttt{seed}, especifica cada uma das funções.

Na implementação do filtro neste trabalho (\textit{BloomFilter.m}) foi desenvolvida uma classe, baseada num \textit{Counting Bloom-filter} (conta-se o número de vezes que cada elemento é adicionado ao filtro), com 5 atributos:
\begin{description}
\item[k]
Número de funções de \textit{hashing} utilizadas.
\item[byteArray]
Limite de vezes que o contador de cada posição é incrementado (255).
\item[arraySize]
Tamanho do vetor de \textit{bits}.
\item[amountAdded]
Número total de elementos adicionados ao \textit[array].
\item[expectedMaxSize]
Tamanho do conjunto que se pretende adicionar do vetor.
\end{description}

No construtor da classe, são calculados os valores do tamanho do vetor (\texttt{arraySize}) e do número de funções de \textit{hash} necessárias, consoante os valores passados como argumentos do próprio construtor, a probabilidade de falsos positivos, isto é, o erro esperado (\texttt{falsePositiveProbability}) e o tamanho do conjunto que se pretende adicionar ao vetor (\texttt{expectedMaxSize}). 

Assumindo que a probabilidade de falsos positivos $p$ é

$$ p =  \left(1 - e^{-\frac{km}{n}}\right)^k $$

e, usando o tamanho do vetor de \textit{bits} $n$ e o tamanho do conjunto que queremos adicionar ao filtro $m$,

$$ a = \left(1 - \frac{1}{n}\right)^m $$

para determinar o número $k$ ótimo de funções de \textit{hashing} que se devem utilizar, deduz-se que

$$ \ln p = k * \ln \left(1 - a^k\right) \\
\Leftrightarrow k =  \frac{n * \ln 2}{m}$$

A partir das fórmulas acima encontradas, também se deduz que

$$ n = \frac{m * \ln \left(\frac{1}{p}\right)}{\left(\ln 2\right) ^ 2} $$

Para além do construtor, existem também métodos para adicionar e verificar a existência de elementos no filtro.

\begin{description}
\item[getIndexes]
Devolve os vários índices para os quais a função de \textit{hashing} aplicada à \textit{string} passada como argumento aponta.
\item[add]
Adiciona um elemento ao filtro.
\item[contains]
Verifica se o elemento passado como argumento existe no filtro (poderá haver ocorrência de falsos positivos).
\item[count]
Devolve o número de vezes que um dado elemento foi adicionado ao vetor.
\item[remove]
Remove do filtro, caso exista, o elemento passado como argumento.
\item[maxCount]
Devolve o número máximo de vezes que um elemento foi adicionado ao vetor.
\item[minCount]
O inverso da função \texttt{maxCount}.
\item[Setters]
Coleção de funções utilizadas para modificar os atributos do \textit{Bloom-filter}, caso o campo \texttt{debug} (argumento passado ao construtor) esteja com o valor 1.
\end{description}

\section{Testes}
\label{sec.bloomtests}

Para testar este módulo, foram desenvolvidos diversos, de entre os quais uns para verificar qual seria o número ideal de funções de \textit{hashing} (\texttt{k}) e outro para verificar o tamanho ideal do vetor de \textit{bits} (\texttt{n}).

No entanto, também foram realizados outros testes relativamente às funções de \textit{hashing} utilizadas pelo \textit{Bloom-filter}.

\subsection{Distribuição de funções de \textit{hashing}}
\label{subsec.hashdist}

Este módulo (\textit{test\_hashFunction\_distribution.m}) tem como principalmente objetivo provar que as funções de \textit{hashing} têm uma distribuição uniforme, para diversos valores de \texttt{k} (neste caso, irá variar entre 1 e 10).

A família de funções de \textit{hashing} usada tanto no filtro como nos testes é designada por \textit{FarmHash}, desenvolvida pela Google. Foi apenas criada uma interface para que pudesse ser usada em Matlab.

Neste teste, foi gerado um conjunto de \textit{strings} aleatórias, usando a função \texttt{generateStrings}, que aceita como argumentos o tamanho do conjunto que devolverá e o tamanho máximo das \textit{strings} que irá gerar (caso o terceiro argumento seja 0, elas terão tamanho fixo, caso contrário, será definido como tamanho máximo), e gerados diversos valores de \textit{hashing}, consoante os diversos elementos do conjunto e da \texttt{seed} correspondente.

As distribuições para cada valor de \texttt{k} deverão ser o mais uniformes possíveis, e os resultados comprovam-no, tal como se pode ver nos histogramas da \autoref{fig:hashdist}.

\begin{figure}[ht]	
\center
\fbox{\includegraphics[height=5cm]{img/test_HashFunction_distribution}}
\caption{Resultados das distribuições das \texttt{k} funções de \textit{hashing}}
\label{fig:hashdist}
\end{figure}

\subsection{Correlação das funções de \textit{hashing}}
\label{subsec.hashcorr}

Para que se possam ser utilizar as várias funções de \textit{hashing}, é necessário que as mesmas sejam descorrelacionadas, isto é, que o coeficiente de correlação seja 0. No entanto, neste caso, considerar-se-á um erro de 0.01 (é quase impossível que os valores sejam iguais a zero, portanto, aceita-se esta ligeira variação).

Este módulo encontra-se no ficheiro \textit{test\_hashFunction\_correlation.m} e, tal como noutros testes, gerar-se-á um \textit{set} de \textit{strings} aleatórias e os respetivos valores de \textit{hashing} para diferentes valores de \texttt{k}, a variar entre 1 e 10. Foi também criada uma matriz de dimensões \texttt{k} por \texttt{numTests}, isto é, cada linha terá diferentes valores de \textit{hashing} para um mesmo valor de \texttt{k}. De seguida, calcular-se-ão os coeficientes de correlação entre de cada conjunto de \textit{hash codes} (linha) desses mesmos valores com o auxílio da função \texttt{corrcoef} (calcula o coeficiente de correlação entre dois conjuntos, neste caso, duas linhas distintas).

Por fim, é gerado um gráfico recorrendo à função \texttt{surf} para mostrar os valores de correlação resultantes. Como verificamos, todos os valores situam-se abaixo do erro assumido (à exceção dos valores em que assumimos o mesmo valor de \texttt{k}, isto é, compararmos a mesma linha, sendo que, nesse caso, o valor será 1), daí se poder considerar que as funções de \texttt{hashing} são descorrelacionadas, tal como se pretendia.

\begin{figure}[ht]	
\center
\fbox{\includegraphics[height=5cm]{img/test_HashFunction_decorrelation}}
\caption{Resultados do teste de correlação de \texttt{k} funções de \textit{hashing}}
\label{fig:hashcorr}
\end{figure}

\subsection{Independência das funções de \textit{hashing}}
\label{subsec.hashindep}

Para além do teste de correlação, foi também efetuado um teste de independência das funções de \textit{hashing} (\textit{test\_hashFunction\_independence.m}), adaptado da implementação do professor António Teixeira. A independência implica descorrelação, e com isto, pode-se provar com qualquer um dos testes que as funções são descorrelacionadas. O objetivo é provar que cada par de colunas é independente entre si.

Primeiramente, é criado um \textit{set} de cem mil \textit{strings} aleatórias e, seguidamente, outra matriz dos respetivos \textit{hash codes} com \texttt{k} (neste teste, \texttt{k = 10}) diferentes \textit{seeds}, utilizando a família de funções \textit{FarmHash}, de tamanho \texttt{k} (número de funções de \textit{hashing} que se pretende aplicar) por \texttt{N} (número de testes que se pretendem executar). De seguida, é gerado um vetor de 10 elementos linearmente espaçados (\texttt{x}) entre 0 e \texttt{N}, e, para cada par de colunas, é criada uma matriz (\texttt{pmf}) de dimensão \texttt{length(x) - 1 / length(x) - 1}. Depois, guarda-se em cada elemento da matriz o número de elementos das colunas de \textit{hash codes} que se situam num mesmo intervalo (esse intervalo é definido pelo vetor \texttt{x} já criado).

Por fim, é calculada a matriz de probabilidade conjunta de duas colunas (\textit{PMF - Probability Mass Function}), e, a partir da mesma, são calculados os vetores de probabilidade individuais de cada uma das colunas. Finalmente, é calculado o resultado da multiplicação destes dois últimos vetores (dois acontecimentos A e B são independentes se $P(A\&B) = P(A) * P(B)$), e compara-se com a matriz de probabilidade conjunta.

\begin{figure}[ht]	
\center
\fbox{\includegraphics[height=7cm]{img/test_hashFunction_independence}}
\caption{Resultados do teste de independência de \texttt{k} funções de \textit{hashing}}
\label{fig:hashindep}
\end{figure}

Como os valores da variação de resultados são mínimos (como se observa na \autoref{fig:hashindep} todos os valores rondam os $10^-4$), podemos considerar que a família de funções é independente, o que nos leva a concluir que são descorrelacionadas.

\subsection{Número ideal de funções de \textit{hashing}}
\label{subsec.optimalk}

O programa de teste para o valor de \texttt{k} ideal encontra-se com o nome \textit{test\_optimalK.m}.

Começa-se por criar uma instância da classe de \textit{Bloom-filter} anteriormente desenvolvida (com o campo \texttt{debug} inicializado a 1, para que se possam utilizar as funções de alteração de valores) e gerar dois conjuntos (um dos quais será adicionado ao filtro, outro não) distintos de cem mil (valor que pode ser alterado) \textit{strings} (como poderá haver \textit{strings} iguais nos \textit{sets}, o tamanho será sempre ligeiramente inferior ao definido anteriormente). De seguida, define-se o tamanho do vetor de \textit{bits} do filtro como oito vezes maior do que o tamanho dos conjuntos de \textit{strings} gerados.

Por fim, itera-se sobre um vetor de \texttt{k} que se definira anteriormente (neste caso, é um vetor com valores de 1 a 15) e, cada ciclo, define-se um \texttt{k} no \textit{Bloom-filter}, adiciona-se os elementos do vetor incialmente escolhido como aquele que se iria adicionar ao filtro e verifica-se se algum dos elementos do outro conjunto de \textit{strings} pertence ou não ao filtro. Caso pertença, é incrementado um contador, para, no final do ciclo, ser calculada a probabilidade de falsos positivos.

\begin{figure}[ht]	
\center
\fbox{\includegraphics[height=5cm]{img/test_OptimalK}}
\caption{Resultados do teste do valor ideal de funções de \textit{hashing} (\texttt{k})}
\label{fig:optimalk}
\end{figure}

De acordo com o gráfico da \autoref{fig:optimalk}, usando a fórmula 

$$ p =  \left(1 - e^{-\frac{km}{n}}\right)^k $$

para determinar a probabilidade de falsos positivos (teórica) para diferentes valores de \texttt{k} e usando os valores do teste acima, verificamos que as diferenças entre o valor teórico e observado são mínimas (o que significa que a função de \textit{hashing} devolve excelentes resultados, mas isso será abordado mais abaixo), e que o valor ideal é 6, para a função de \textit{hashing} em questão. Para uma função diferente, os valores poderão diferir.

\subsection{Número ideal do vetor de \textit{bits}}
\label{subsec.optimaln}

O módulo para o teste do valor ideal do tamanho do vetor \texttt{n} encontra-se no ficheiro \textit{test\_optimalN.m}.

Tal como no teste do \autoref{subsec.optimalk}, também são criados dois conjuntos de \texttt{strings} aleatórias com o mesmo propósito, um para ser adicionado ao filtro e o outro não. É também criado um vetor com diferentes valores de \texttt{n}, que vão desde o tamanho dos conjuntos de \textit{strings} até 10 vezes esse valor, com uma diferença de metade do mesmo valor entre cada.

De seguida, itera-se sobre os valores deste último vetor de valores e vai-se criando uma instância de um \textit{Bloom-filter} com os valores de \texttt{n} (\texttt{arraySize}) e \texttt{k} (depende do tamanho do vetor) a cada passagem. Adiciona-se um dos conjuntos de \textit{strings}, verifica-se a existência dos elementos do outro que não foi adicionado e, por fim, calcula-se a probabilidade de falsos positivos, tal como no teste anterior.

\begin{figure}[ht]	
\center
\fbox{\includegraphics[height=5cm]{img/test_OptimalN_img}}
\caption{Resultados o teste do tamanho ideal do vetor de \textit{bits} (\texttt{arraySize} / \texttt{n})}
\label{fig:optimalnimg}
\end{figure}

Como se verifica no gráfico da \autoref{fig:optimalnimg}, à medida que o tamanho do \textit{array} aumenta, a probabilidade de falsos positivos diminui, isto é, são inversamente proporcionais.

Os valores ideias são os presentes na \autoref{fig:optimalntext}

\begin{figure}[ht]	
\center
\fbox{\includegraphics[height=5cm]{img/test_OptimalN_txt}}
\caption{Resultados ideias do tamanho ideal do vetor de \textit{bits} (\texttt{arraySize} / \texttt{n})}
\label{fig:optimalntext}
\end{figure}

\subsection{Testes práticos do \textit{Bloom-filter}}
\label{subsec.testebloom}

Foram desenvolvidos dois módulos semelhantes para um teste mais direcionado ao uso real de um \textit{Bloom-filter}. Estão em dois ficheiros distintos, \textit{test\_big\_BloomFilter.m} e \textit{test\_small\_BloomFilter.m}.

O primeiro segue o modelo dos testes anteriores, em que se gera dois \textit{sets} de um certo tamanho (neste caso, cem mil elementos) de \textit{strings} aleatórias, cria-se uma instância de um \textit{Bloom-filter} com uma probabilidade de falsos positivos de 0.0001\%, adiciona-se um dos conjuntos ao filtro e verifica-se a existência de falsos positivos. Por fim, compara-se o resultado observado da probabilidade de falsos positivos com a que se definiu aquando a criação do filtro. O objetivo é que os resultados sejam o mais próximos possíveis, algo que se conseguiu atingir em ambos os testes.

No segundo teste (\textit{small}), contrariamente ao primeiro em que se geram os conjuntos, definem-se conjuntos muito pequenos inicialmente e, depois, executa-se o mesmo processo que o anterior.

\begin{figure}[ht]	
\center
\fbox{\includegraphics[height=5cm]{img/test_big_BloomFilter}}
\caption{Resultados da execução de \textit{test\_big\_BloomFilter.m}}
\label{fig:testbigbloom}
\end{figure}


\chapter{Locality-Sensitive Hashing}
\label{chap.lsh}

O \textit{Locality-Sensitive Hashing} é particularmente útil quando se têm grandes conjuntos de documentos e se pretende achar semelhantes entre si, como, por exemplo, achar notícias semelhantes em diversos \textit{websites}. No entanto, pequenos trechos dos documentos podem aparecer noutros não necessarimente na mesma ordem. Para além do mais, se tivermos \textit{sets} na ordem dos milhões e milhares de milhão, são tantas as comparações que são necessárias fazer que excedem a memória disponível.

Portanto, para podermos comparar documentos, são necessários 3 passos:

\begin{description}
\item[Shingling]
Converter documentos para conjuntos.
\item[Min-Hashing]
Converter grandes conjuntos para pequenas assinaturas (por norma, de inteiros), preservando a similariedade.
\item[Locality-Sensitive Hashing]
Forcar-se apenas nos pares de assinaturas que possivelmente pertençam a documentos semelhantes e, mais tarde, testar realmente a sua similariedade.
\end{description}

O módulo de \textit{LSH} está no ficheiro \textit{LSH.m} e dispõe dos seguintes métodos:

\begin{description}
\item[shingleWords]
Aceita um \textit{cell array} com o conteúdo de um documento e devolve \textit{shingles} relativos ao mesmo.
\item[signature]
Converte um vetor de \textit{shingles} num vetor de assinaturas, através do processo de \textit{min-hashing}.
\item[candidates]
Devolve a lista de documentos candidatos a serem semelhantes a outros, consoante a matrix de assinaturas e o \textit{threshold} passados como argumentos.
\item[candidates\_to]
Executa o mesmo processo que a função \texttt{candidates}, no entanto, em vez de aceitar apenas uma matriz de assinaturas, aceita também a assinatura de um documento, o qual pretendemos comparar com os restantes.
\item[similars]
Verifica quais são os documentos realmente semelhantes e a sua Similariedade de Jaccard, consoante a matriz de candidatos, assinaturas e o \textit{threshold} passados como argumentos.
\item[similiars\_to]
Tem a mesma função que \texttt{similars}, no entanto, aplica-se ao caso em que pretendemos comparar um documento com os restantes.
\end{description}

O único construtor do módulo aceita apenas um argumento, que é o erro esperado (\texttt{expectedError}). Este erro será utilizado para calcular o número \texttt{k} de \textit{hash functions} necessárias, que é também o único atributo que o módulo possui, segundo a fórmula:

$$ k = 1 / expectedError^2 $$

\subsection{Shingling}
\label{subsec.shingling}

Uma \textit{k-shingle} de um documento é uma sequência de k \textit{tokens} (palavras, caracteres, etc.) que aparecem no documento. Documentos que tenham muitas \textit{shingles} em comum, possuem texto parecido, mesmo que o mesmo não apareça na mesma ordem.

A similariedade entre dois documentos ($D1, D2$) pode ser calculada através da Similariedade de Jaccard:

$$ sim(D1, D2) = \frac{|C1\cap C2|}{|C1\cup C2|} $$

sendo $C1$ e $C2$ os conjuntos de \textit{shingles} de $D1$ e $D2$, respetivamente.

A Distância de Jaccard, por outro lado, pode ser dada por:

$$ d(D1, D2) = 1 - sim(D1, D2) $$

Para gerar um \textit{set} de \textit{shingles} é utilizada a função \texttt{shingleWords}, que recebe como argumento um \textit{cell array}, neste caso, de \textit{strings} (considere-se o mesmo \texttt{Doc}). Para gerar esse conjunto, é necessário selecionar quais as sequências de palavras mais importantes de \texttt{Doc}. Para tal, é necessária a criação de um \textit{set} de \textit{stop words}, logo, foram guardadas num \textit{cell array} \texttt{stop\_words} as cem palavras mais comuns da língua inglesa. Quando o programa encontra uma \textit{stop word}, ele guarda a sequência \textit{stop\_word next\_word1 next\_word2} num outro \textit{cell array}, que será o retorno da função.

\subsection{Min-Hashing}
\label{subsec.minhash}

Para contornar as demoras que as comparações de excertos de textos provocariam, os \textit{shingles} são convertidos em assinaturas de inteiros, no entanto, a sua similariedade deve ser conservada.

Para a criação das respetivas assinaturas é usada a função \texttt{signature}; começa-se por se criar um vetor em que o seu valor inicial é o valor máximo do tipo \textit{double} (auxilia no cálculo dos valores mínimos) e, de seguida, para cada valor de \texttt{k} (número de \textit{hash functions}), é gerado um vetor das assinaturas do \textit{cell array} de \textit{shingles} que é passado como argumento, dos quais é extraído o valor mínimo e guardado no \textit{array} mais tarde devolvido pela função.

\subsection{Locality-Sensitive Hashing}
\label{subsec.lsh}

Por fim, depois de gerados os vetores de assinaturas dos documentos, basta compará-los e ver quais aqueles que mais se assemelham.

Primeiramente, começa-se por definir uma lista de candidatos possíveis (onde é provável a ocorrência de falsos positivos), para, por fim, verificar quais são mesmo os documentos que são realmente semelhantes (segundo um coeficiente de Similariedade - \textit{threshold}).

A função \texttt{candidates}, definida no módulo \texttt{LSH}, serve para definir a lista de candidatos possíveis. Consideremos a matriz de assinaturas \textit{M}, em que cada coluna corresponde à assinatura de um documento, isto é, o resultante do processo de \textit{min-hashing} dos \textit{shingles} obtidos.

% Explicar o processo de encontrar r rows e b bands

Cria-se também um \textit{cell array} onde serão armazenados os pares candidatos a serem semelhantes, numa estrutura em que a linha \textit{i} corresponde ao documento \textit{i} e em que cada coluna corresponde ao índice \textit{j} de um documento possível candidato semelhante ao documento \textit{i}.

De seguida, itera-se sobre cada uma das bandas que se extraem da matriz de assinaturas e compara-se com todas as outras bandas existentes (verica-se se a soma do número de assinaturas que as bandas têm em comum é igual ao número de \textit{rows}).

Por fim, a função \texttt{similars} trata de finalizar o processo e devolver os documentos que são realmente semelhantes e o seu coeficiente de similariedade.

Itera-se sobre a matriz de candidatos e compara-se, uma a uma, se a Similariedade de Jaccard entre as assinaturas é maior que o \textit{threshold} definido (usando a função \texttt{intersect}, que devolve os elementos em comum entre dois conjuntos). Se a condição se verifica, adiciona-se ao vetor de retorno os índices na matriz de assinaturas dos documentos em questão e o valor da sua similariedade.

\subsection{Testes}
\label{subsec.lshtests}
Para os testes deste módulo, foram adaptados os \textit{scripts} do Guião Prático-Laboratorial 07 da disciplina, mas, para além de ser usado o \textit{dataset} de cem mil utilizadores da MovieLens, foi também utilizado o que contém um milhão de utilizadores.

A única diferença entre os testes é apenas o \textit{dataset} utilizado, pois o processo tem de obrigatoriamente ser o mesmo, apenas se muda o tamanho do conjunto de dados.

Inicia-se o teste obtendo um vetor com todos os utilizadores a partir do \textit{dataset}. De seguida, para cada utilizador, constrói-se o conjunto de \textit{shingles} (neste caso, não é usada a função \texttt{shingleWords} do módulo \texttt{LSH}, visto que não é documento de texto, mas sim um vetor de de índices de filmes que cada utilizador avaliou) e respetivas assinaturas, usando a função \texttt{signature}. 

Primeiro, vai ser calculada a Similariedade de Jaccard esperada (teórica), simplesmente iterando sobre o conjunto de assinaturas e, usando a fórmula 

$$ sim(D1, D2) = \frac{|C1\cap C2|}{|C1\cup C2|} $$

e as funções de Matlab \texttt{intersection} (devolve os elementos que dois conjuntos têm em comum) e \texttt{union} (devolve a união de dois conjuntos). Por fim, verifica-se, quais destes valores estão a acima do \textit{threshold} assumido (nestes teste, assumiu-se 0.6). Os resultados mostram que existem apenas 3 documentos com uma similariedade acima dos 0.6, como se verifica na \autoref{fig:test100ke}.

\begin{figure}[ht]	
\center
\fbox{\includegraphics[height=2cm]{img/test_LSH_100k_Exp}}
\caption{Resultados (valores esperados) do teste com 100 mil utilizadores}
\label{fig:test100ke}
\end{figure}

Finalmente, para calcular a Similariedade de Jaccard observada (experimental), gera-se a lista de candidatos usando a função \texttt{candidates} do módulo \texttt{LSH} e a matriz com os documentos similares usando a função \texttt{similars}, também do mesmo módulo.

A \autoref{fig:test100ko} mostra que os resultados de ambos os testes foram os mesmos, havendo apenas uma pequeníssima variação dos valores de similariedade (à volta de 0.2).

\begin{figure}[ht]	
\center
\fbox{\includegraphics[height=2cm]{img/test_LSH_100k_Obs}}
\caption{Resultados (valores observados) do teste com 100 mil utilizadores}
\label{fig:test100ko}
\end{figure}

% Falta teste com dataset de 1m

\chapter{SPAM Filter}
\label{chap.spamfilter}

SPAM Filter.

\chapter{Conclusões}
\label{chap.conclusões}

\maketitle
\nocite{*}
\printbibliography[title={Referências}]

\end{document}
